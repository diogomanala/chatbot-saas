// For√ßa o carregamento das vari√°veis de ambiente ANTES de qualquer coisa
import { config } from 'dotenv'
import path from 'path'

// Carrega .env.local primeiro
config({ path: path.resolve(process.cwd(), '.env.local') })
// Carrega .env como fallback
config({ path: path.resolve(process.cwd(), '.env') })

import OpenAI from 'openai'
import { supabaseAdmin } from './supabase-admin'
import { billingService } from './billing.service'
import { calculateCreditCost } from '../../packages/shared/pricing'

interface ChatbotConfig {
  id: string
  name: string
  openai_model: string
  temperature: number
  system_prompt: string
  company_prompt?: string
  training_prompt?: string
  response_rules?: string
  org_id: string
  is_active: boolean
  working_hours_start?: number;
  working_hours_end?: number;
  out_of_hours_message?: string;
}

interface ChatMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

class OpenAIService {
  private openai: OpenAI

  constructor() {
    // Log para debug das vari√°veis de ambiente
    console.log('üîß [OpenAI] Inicializando OpenAI Service');
    console.log('üîß [OpenAI] OPENAI_API_KEY presente:', !!process.env.OPENAI_API_KEY);
    console.log('üîß [OpenAI] OPENAI_API_KEY valor bruto:', JSON.stringify(process.env.OPENAI_API_KEY));
    
    let apiKey = process.env.OPENAI_API_KEY;
    
    // Remove aspas se existirem
    if (apiKey && (apiKey.startsWith('"') && apiKey.endsWith('"'))) {
      console.log('üîß [OpenAI] Removendo aspas da API key...');
      apiKey = apiKey.slice(1, -1);
    }
    
    console.log('üîß [OpenAI] OPENAI_API_KEY processada:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined');
    
    if (!apiKey) {
      throw new Error('OPENAI_API_KEY n√£o encontrada nas vari√°veis de ambiente');
    }

    this.openai = new OpenAI({
      apiKey: apiKey,
    });
  }

  /**
   * Busca configura√ß√£o do chatbot com isolamento por organiza√ß√£o
   */
  async getChatbotConfig(chatbotId: string, orgId: string): Promise<ChatbotConfig | null> {
    try {
      const { data: chatbot, error } = await supabaseAdmin
        .from('chatbots')
        .select(`
          id,
          name,
          groq_model,
          temperature,
          system_prompt,
          company_prompt,
          training_prompt,
          response_rules,
          org_id,
          is_active,
          business_context,
          fallback_message,
          auto_response_enabled,
          default_fallback_enabled,
          working_hours_start,
          working_hours_end,
          out_of_hours_message
        `)
        .eq('id', chatbotId.toString())
        .eq('org_id', orgId.toString())
        .eq('is_active', true)
        .single()

      if (error || !chatbot) {
        console.error('Chatbot n√£o encontrado ou inativo:', error)
        return null
      }

      // Padronizar campos e aplicar defaults seguros
      const config = {
        ...chatbot,
        // Padronizar modelo - usar default se vazio
        model: chatbot.groq_model || 'gpt-4o-mini',
        model_provider: 'openai', // Sempre OpenAI para este servi√ßo
        // Padronizar campo de treinamento
        systemPrompt: this.buildSystemPrompt(chatbot),
        // Aplicar defaults seguros
        temperature: chatbot.temperature ?? 0.3,
        top_p: 1.0, // Default padr√£o
        // Mapear para compatibilidade
        openai_model: this.mapToOpenAIModel(chatbot.groq_model || 'gpt-4o-mini')
      } as ChatbotConfig

      // Log de valida√ß√£o do modelo
      if (!chatbot.groq_model) {
        console.warn(`‚ö†Ô∏è [OpenAI] Chatbot ${chatbot.name} sem modelo definido, usando default: gpt-4o-mini`)
      }

      return config
    } catch (error) {
      console.error('Erro ao buscar configura√ß√£o do chatbot:', error)
      return null
    }
  }

  /**
   * Mapeia modelos Groq para modelos OpenAI equivalentes
   */
  private mapToOpenAIModel(groqModel: string): string {
    const modelMap: { [key: string]: string } = {
      'llama-3.1-70b-versatile': 'gpt-3.5-turbo',
      'llama-3.3-70b-versatile': 'gpt-3.5-turbo',
      'llama-3.1-8b-instant': 'gpt-3.5-turbo',
      'mixtral-8x7b-32768': 'gpt-3.5-turbo',
      'gemma2-9b-it': 'gpt-3.5-turbo'
    }
    
    return modelMap[groqModel] || 'gpt-3.5-turbo'
  }

  /**
   * Constr√≥i o prompt do sistema personalizado baseado no treinamento
   */
  private buildSystemPrompt(config: ChatbotConfig): string {
    let systemPrompt = config.system_prompt

    console.log(`üîç [OpenAI] System prompt original do chatbot ${config.name}:`, systemPrompt);

    // Adiciona contexto da empresa se dispon√≠vel
    if (config.company_prompt) {
      systemPrompt += `\n\nContexto da Empresa:\n${config.company_prompt}`
    }

    // Adiciona treinamento personalizado se dispon√≠vel
    if (config.training_prompt) {
      systemPrompt += `\n\nTreinamento Personalizado:\n${config.training_prompt}`
    }

    // Adiciona regras de resposta se dispon√≠veis
    if (config.response_rules) {
      systemPrompt += `\n\nRegras de Resposta:\n${config.response_rules}`
    }

    // Adiciona instru√ß√µes espec√≠ficas para isolamento
    systemPrompt += `\n\nIMPORTANTE: Voc√™ deve responder apenas com base nas informa√ß√µes fornecidas neste prompt e no contexto desta conversa espec√≠fica. N√£o utilize informa√ß√µes de outras conversas ou contextos.`

    console.log(`üîç [OpenAI] System prompt final constru√≠do:`, systemPrompt);

    return systemPrompt
  }

  /**
   * Gera resposta usando OpenAI com treinamento personalizado e d√©bito autom√°tico de cr√©ditos
   */
  // M√©todo para gerar resposta usando OpenAI
  async generateResponse(
    chatbot: any, // Aceitar objeto chatbot completo
    message: string,
    conversationHistory: any[] = [],
    correlationId?: string
  ): Promise<{ response: string; tokensUsed: number } | null> {
    const logPrefix = correlationId ? `[${correlationId}]` : '';
    
    try {
      console.log(`üöÄ ${logPrefix} [OPENAI] Iniciando generateResponse`);
      console.log(`üîç ${logPrefix} [OPENAI] Par√¢metros:`, { 
        chatbotId: chatbot.id, 
        orgId: chatbot.org_id, 
        messageLength: message.length 
      });

      // VALIDA√á√ÉO 1: Model n√£o pode estar vazio
      const model = chatbot.groq_model || chatbot.model || 'gpt-4o-mini';
      if (!model || model.trim() === '') {
        console.warn(`‚ö†Ô∏è ${logPrefix} [OPENAI] WARNING: Chatbot ${chatbot.name} sem model definido, usando default gpt-4o-mini`);
        chatbot.model = 'gpt-4o-mini';
      } else {
        chatbot.model = model;
      }

      // VALIDA√á√ÉO 2: System prompt deve ter pelo menos 20 caracteres
      if (!chatbot.system_prompt || chatbot.system_prompt.trim().length < 20) {
        console.error(`‚ùå ${logPrefix} [OPENAI] ERRO: Chatbot ${chatbot.name} sem treinamento configurado adequadamente`);
        console.error(`üîç ${logPrefix} [OPENAI] System prompt atual:`, chatbot.system_prompt);
        
        // Retornar mensagem de fallback espec√≠fica
        return {
          response: "Desculpe, este chatbot ainda n√£o foi configurado adequadamente. Entre em contato com o suporte para configurar o treinamento do assistente.",
          tokensUsed: 0
        };
      }

      // LOGS OBRIGAT√ìRIOS: provider, model e primeiros 100 chars do system prompt
      console.log(`üìä ${logPrefix} [OPENAI] Configura√ß√£o validada:`, {
        provider: 'openai',
        model: chatbot.model,
        systemPromptPreview: chatbot.system_prompt.substring(0, 100) + (chatbot.system_prompt.length > 100 ? '...' : ''),
        systemPromptLength: chatbot.system_prompt.length
      });

      // Verificar cr√©ditos suficientes
      const estimatedTokens = this.estimateTokens(message);
      const hasCredits = await this.checkCredits(chatbot.org_id, estimatedTokens);
      
      if (!hasCredits) {
        console.error(`‚ùå ${logPrefix} [OPENAI] Cr√©ditos insuficientes para org ${chatbot.org_id}`);
        return null;
      }

      // Construir system prompt final com defaults seguros
      const systemPrompt = this.buildSystemPromptWithDefaults(chatbot);
      
      console.log(`üîç ${logPrefix} [OPENAI] System prompt constru√≠do (${systemPrompt.length} chars)`);

      // Buscar hist√≥rico da conversa (√∫ltimas 10 mensagens)
      const { data: recentMessages } = await supabaseAdmin
        .from('messages')
        .select('direction, message_content, created_at')
        .eq('chatbot_id', chatbot.id)
        .order('created_at', { ascending: false })
        .limit(10);

      const messages = [
        { role: 'system', content: systemPrompt },
        ...(recentMessages || []).reverse().map((msg: any) => ({
          role: msg.direction === 'inbound' ? 'user' : 'assistant',
          content: msg.message_content
        })),
        { role: 'user', content: message }
      ];

      console.log(`üîç ${logPrefix} [OPENAI] Preparando chamada para API com ${messages.length} mensagens`);

      const completion = await this.openai.chat.completions.create({
        model: this.mapToOpenAIModel(chatbot.model),
        messages: messages as any,
        temperature: chatbot.temperature ?? 0.3,
        top_p: 1.0,
        max_tokens: chatbot.max_tokens || 1000,
      });

      const response = completion.choices[0]?.message?.content;
      const tokensUsed = completion.usage?.total_tokens || 0;

      if (!response) {
        console.error(`‚ùå ${logPrefix} [OPENAI] Resposta vazia da API`);
        return null;
      }

      console.log(`‚úÖ ${logPrefix} [OPENAI] Resposta gerada com sucesso: ${tokensUsed} tokens`);
      
      return {
        response: response.trim(),
        tokensUsed
      };

    } catch (error: any) {
      console.error(`‚ùå ${logPrefix} [OPENAI] Erro ao gerar resposta:`, error);
      
      if (error.code === 'insufficient_quota') {
        console.error(`üí≥ ${logPrefix} [OPENAI] Cota da API OpenAI esgotada`);
      } else if (error.code === 'rate_limit_exceeded') {
        console.error(`‚è±Ô∏è ${logPrefix} [OPENAI] Rate limit da API OpenAI excedido`);
      }
      
      return null;
    }
  }

  /**
   * Constr√≥i o prompt do sistema com defaults seguros
   */
  private buildSystemPromptWithDefaults(chatbot: any): string {
    // Prefixo padr√£o seguro
    const defaultPrefix = `Voc√™ √© o chatbot ${chatbot.name} da organiza√ß√£o. `;
    
    let systemPrompt = chatbot.system_prompt || '';
    
    // Se n√£o tem system_prompt, usar apenas o prefixo padr√£o
    if (!systemPrompt || systemPrompt.trim().length < 20) {
      systemPrompt = defaultPrefix + "Responda de forma √∫til e prestativa √†s perguntas dos usu√°rios.";
    } else {
      // Concatenar prefixo com o treinamento existente
      systemPrompt = defaultPrefix + systemPrompt;
    }

    // Adiciona contexto da empresa se dispon√≠vel
    if (chatbot.company_prompt) {
      systemPrompt += `\n\nContexto da Empresa:\n${chatbot.company_prompt}`;
    }

    // Adiciona treinamento personalizado se dispon√≠vel
    if (chatbot.training_prompt) {
      systemPrompt += `\n\nTreinamento Personalizado:\n${chatbot.training_prompt}`;
    }

    // Adiciona regras de resposta se dispon√≠veis
    if (chatbot.response_rules) {
      systemPrompt += `\n\nRegras de Resposta:\n${chatbot.response_rules}`;
    }

    // Adiciona instru√ß√µes espec√≠ficas para isolamento
    systemPrompt += `\n\nIMPORTANTE: Voc√™ deve responder apenas com base nas informa√ß√µes fornecidas neste prompt e no contexto desta conversa espec√≠fica. N√£o utilize informa√ß√µes de outras conversas ou contextos.`;

    return systemPrompt;
  }

  /**
   * Extrai uso de tokens da resposta da API OpenAI
   * üî• CORRE√á√ÉO ROBUSTA: NUNCA retorna 0 tokens - sempre calcula fallback
   */
  private extractTokenUsage(completion: any): { inputTokens: number; outputTokens: number } {
    try {
      // Tenta extrair tokens reais da API
      const realInputTokens = completion.usage?.prompt_tokens || 0
      const realOutputTokens = completion.usage?.completion_tokens || 0
      
      // Se temos tokens reais v√°lidos, usa eles
      if (realInputTokens > 0 && realOutputTokens > 0) {
        console.log('[OpenAIService] ‚úÖ Tokens reais extra√≠dos:', { realInputTokens, realOutputTokens })
        return {
          inputTokens: realInputTokens,
          outputTokens: realOutputTokens
        }
      }
      
      // üî• FALLBACK ROBUSTO: Se n√£o temos tokens reais, calcula estimativa
      console.warn('[OpenAIService] ‚ö†Ô∏è completion.usage inv√°lido, calculando fallback:', completion.usage)
      
      // Estima tokens baseado no conte√∫do da resposta
      const responseContent = completion.choices?.[0]?.message?.content || ''
      const estimatedOutputTokens = Math.max(Math.ceil(responseContent.length / 4), 50) // M√≠nimo 50 tokens
      const estimatedInputTokens = Math.max(Math.ceil(estimatedOutputTokens * 0.3), 30) // M√≠nimo 30 tokens de input
      
      console.log('[OpenAIService] üîÑ Tokens estimados (fallback):', { 
        estimatedInputTokens, 
        estimatedOutputTokens,
        responseLength: responseContent.length 
      })
      
      return {
        inputTokens: estimatedInputTokens,
        outputTokens: estimatedOutputTokens
      }
    } catch (error) {
      console.error('[OpenAIService] ‚ùå Erro ao extrair tokens, usando fallback de emerg√™ncia:', error)
      
      // üî• FALLBACK DE EMERG√äNCIA: Valores m√≠nimos garantidos
      const emergencyInputTokens = 100  // M√≠nimo absoluto
      const emergencyOutputTokens = 150 // M√≠nimo absoluto
      
      console.log('[OpenAIService] üö® Usando fallback de emerg√™ncia:', { 
        emergencyInputTokens, 
        emergencyOutputTokens 
      })
      
      return { 
        inputTokens: emergencyInputTokens, 
        outputTokens: emergencyOutputTokens 
      }
    }
  }

  /**
   * Estima o n√∫mero de tokens em um texto (aproxima√ß√£o simples)
   */
  private estimateTokens(text: string): number {
    // Aproxima√ß√£o: 1 token ‚âà 4 caracteres para texto em portugu√™s/ingl√™s
    return Math.ceil(text.length / 4)
  }

  /**
   * Verifica se a organiza√ß√£o tem cr√©ditos suficientes
   */
  private async checkCredits(orgId: string, estimatedTokens: number): Promise<boolean> {
    try {
      const estimatedCredits = calculateCreditCost(estimatedTokens, estimatedTokens);
      const hasSufficientCredits = await billingService.hasSufficientCredits(orgId, estimatedCredits);
      
      if (!hasSufficientCredits) {
        console.warn(`‚ö†Ô∏è [OpenAI] Cr√©ditos insuficientes para org ${orgId}. Estimativa: ${estimatedCredits} cr√©ditos`);
        return false;
      }
      
      return true;
    } catch (error) {
      console.error(`‚ùå [OpenAI] Erro ao verificar cr√©ditos:`, error);
      return false;
    }
  }

  /**
   * Valida se um modelo OpenAI est√° dispon√≠vel
   */
  async validateModel(model: string): Promise<boolean> {
    try {
      const models = await this.openai.models.list()
      return models.data.some(m => m.id === model)
    } catch (error) {
      console.error('Erro ao validar modelo:', error)
      return false
    }
  }

  /**
   * Lista modelos dispon√≠veis na API OpenAI
   */
  async getAvailableModels(): Promise<string[]> {
    try {
      const models = await this.openai.models.list()
      return models.data.map(m => m.id)
    } catch (error) {
      console.error('Erro ao listar modelos:', error)
      return []
    }
  }

  /**
   * Testa a conectividade com a API OpenAI
   */
  async testConnection(): Promise<boolean> {
    try {
      console.log('üîß [OpenAI] Testando conex√£o...');
      const models = await this.openai.models.list();
      console.log('üîß [OpenAI] Conex√£o bem-sucedida! Modelos encontrados:', models.data.length);
      return true
    } catch (error) {
      console.error('‚ùå [OpenAI] Erro de conectividade:', error)
      return false
    }
  }
}

// Inst√¢ncia singleton do servi√ßo
export const openaiService = new OpenAIService()
export default openaiService